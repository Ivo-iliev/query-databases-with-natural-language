{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851893e-f3cc-4ce6-9b74-c5ac10a436ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install ipywidgets\n",
    "# !pip install sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3aefd-00b6-47c5-996a-99f44006b85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "# import sentencepiece\n",
    "import pandas as pd\n",
    "from anthropic import Anthropic\n",
    "CLAUDE = Anthropic()\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import codecs\n",
    "import uuid\n",
    "from transformers import LlamaTokenizer\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "REDSHIFT=boto3.client('redshift-data')\n",
    "S3=boto3.client('s3')\n",
    "from botocore.config import Config\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "config = Config(\n",
    "    read_timeout=120,\n",
    "    retries = dict(\n",
    "        max_attempts = 4\n",
    "    )\n",
    ")\n",
    "BEDROCK=boto3.client(service_name='bedrock-runtime',region_name='us-east-1',config=config)\n",
    "MIXTRAL_ENDPOINT=\"mixtral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7b0a8-f945-44eb-b85d-2364aedf9050",
   "metadata": {},
   "source": [
    "### Deploy Mixtral 8x7B Instruct to SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6570d1a-7948-420f-a3f6-78058efcb496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note this requires an ml.g5.48xlarge instance.\n",
    "model_id = \"huggingface-llm-mixtral-8x7b-instruct\"\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "model = JumpStartModel(model_id=model_id)\n",
    "predictor = model.deploy(endpoint_name=MIXTRAL_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e948f-67b0-4c72-ad33-930071495bed",
   "metadata": {},
   "source": [
    "## REDSHIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ecd78-4240-4339-8a7b-3e77bd8d0824",
   "metadata": {},
   "source": [
    "#### Change parameters below to those of your redshift provisioned cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7227db-c014-4272-a1b7-57babd5232b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redshift_client = boto3.client('redshift-data')\n",
    "CLUSTER_IDENTIFIER = 'redshift-cluster-1'\n",
    "DATABASE = 'dev'\n",
    "DB_USER = 'awsuser' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaacf97-6998-487f-8157-cb27d9a278bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redshift_client = boto3.client('redshift-data')\n",
    "CLUSTER_IDENTIFIER = 'redshift-cluster-1'\n",
    "DATABASE = 'dev'\n",
    "DB_USER = 'awsuser' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39647d0-ec63-43d6-9043-d34cc8e84141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_counter(path):\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(path)\n",
    "    return tokenizer\n",
    "def mixtral_counter(path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af74f-a573-4df3-853f-96b22fba34cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_llm(prompts,tokens):   \n",
    "    \"\"\"\n",
    "    Function to prompt the model to generate SQL statements from natural language\n",
    "    \"\"\"\n",
    "    import boto3 #remove\n",
    "    import json #remove\n",
    "    payload = {\n",
    "        \"inputs\":prompts,\n",
    "        \"parameters\": {\"max_new_tokens\": tokens, \n",
    "                       # \"top_p\": params['top_p'], \n",
    "                       \"temperature\": 0.1,\n",
    "                       \"return_full_text\": False,}\n",
    "    }\n",
    "    llama=boto3.client(\"sagemaker-runtime\")\n",
    "    output=llama.invoke_endpoint(Body=json.dumps(payload), EndpointName=MIXTRAL_ENDPOINT,ContentType=\"application/json\")\n",
    "    answer=json.loads(output['Body'].read().decode())[0]['generated_text']  \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83880841-47bc-490f-920c-56619d011035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qna_llm(prompts,params):\n",
    "    \"\"\"\n",
    "    Function to prompt the model to generate natural language answers from sql results\n",
    "    \"\"\"   \n",
    "    if 'mixtral' in params['model_id'].lower():        \n",
    "        import boto3\n",
    "        import json\n",
    "        payload = {\n",
    "            \"inputs\":prompts,\n",
    "            \"parameters\": {\"max_new_tokens\": params['text-token'], \n",
    "                           # \"top_p\": params['top_p'], \n",
    "                           \"temperature\": params['temp'],\n",
    "                           \"return_full_text\": False,}\n",
    "        }\n",
    "        llama=boto3.client(\"sagemaker-runtime\")\n",
    "        output=llama.invoke_endpoint(Body=json.dumps(payload), EndpointName=MIXTRAL_ENDPOINT,ContentType=\"application/json\")\n",
    "        answer=json.loads(output['Body'].read().decode())[0]['generated_text']   \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec641b4-70a4-45d3-86cb-bd876d15e354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_csv_rows(csv_rows, max_token_per_chunk):\n",
    "    \"\"\"\n",
    "    Chunk CSV rows based on the maximum token count per chunk.\n",
    "    Args:\n",
    "        csv_rows (list): List of CSV rows.\n",
    "        max_token_per_chunk (int, optional): Maximum token count per chunk.\n",
    "    Returns:\n",
    "        list: List of chunks containing CSV rows.\n",
    "    Raises:\n",
    "        ValueError: If a single CSV row exceeds the specified max_token_per_chunk.\n",
    "    \"\"\"\n",
    "    header = csv_rows[0]  # Assuming the first row is the header\n",
    "    csv_rows = csv_rows[1:]  # Remove the header from the list\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "    chunks = []\n",
    "    header_token=len(mixtral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(header))\n",
    "    for row in csv_rows:\n",
    "        token = len(mixtral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(row))\n",
    "        if current_token_count + token+header_token <= max_token_per_chunk:\n",
    "            current_chunk.append(row)\n",
    "            current_token_count += token\n",
    "        else:\n",
    "            if not current_chunk:\n",
    "                raise ValueError(\"A single CSV row exceeds the specified max_token_per_chunk.\")\n",
    "            header_and_chunk=[header]+current_chunk\n",
    "            chunks.append(\"\\n\".join([x for x in header_and_chunk]))\n",
    "            current_chunk = [row]\n",
    "            current_token_count = token\n",
    "\n",
    "    if current_chunk:\n",
    "        last_chunk_and_header=[header]+current_chunk\n",
    "        chunks.append(\"\\n\".join([x for x in last_chunk_and_header]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fc3be-eede-4b2c-a926-8d5c7a04f30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tables_redshift(cluster_identifier, database, db_user, schema):\n",
    "    \"\"\"\n",
    "    Get a list of table names in a specified schema from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the tables.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        schema (str): The schema pattern to filter tables.\n",
    "    Returns:\n",
    "        list: A list of table names in the specified schema.\n",
    "    \"\"\"\n",
    "    tables_ls = REDSHIFT.list_tables(\n",
    "    ClusterIdentifier=cluster_identifier,\n",
    "    Database=database,\n",
    "    DbUser=db_user,\n",
    "    SchemaPattern=schema\n",
    "    )\n",
    "    return [x['name'] for x in  tables_ls['Tables']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e81566-6e5e-4771-9fdd-65343c388f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_db_redshift(cluster_identifier, database, db_user):\n",
    "    \"\"\"\n",
    "    Get a list of databases from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the tables.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of databases in the Redshift cluster.\n",
    "    \"\"\"\n",
    "    db_ls = REDSHIFT.list_databases(\n",
    "    ClusterIdentifier=cluster_identifier,\n",
    "    Database=database,\n",
    "    DbUser=db_user\n",
    "    )\n",
    "    return db_ls['Databases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf5577-7130-4302-a03f-4f5a60db0a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_schema_redshift(cluster_identifier, database, db_user):\n",
    "    \"\"\"\n",
    "    Get a list of schemas from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the schemas.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of schemas in the Redshift cluster.\n",
    "    \"\"\"\n",
    "    schema_ls = REDSHIFT.list_schemas(\n",
    "    ClusterIdentifier=cluster_identifier,\n",
    "    Database=database,\n",
    "    DbUser=db_user\n",
    "    )\n",
    "    return schema_ls['Schemas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f38a84-47bb-481e-a348-4b32ca267b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query_with_pagination( sql_query, cluster_identifier, database, db_user):\n",
    "    \"\"\"\n",
    "    Execute multiple SQL queries in Amazon Redshift with pagination support.\n",
    "    Args:\n",
    "        sql_query1 (str): The first SQL query to execute.\n",
    "        sql_query2 (str): The second SQL query to execute.\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of results from executing the SQL queries.\n",
    "    \"\"\"\n",
    "    results_list=[]\n",
    "    response_b = REDSHIFT.batch_execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sqls=sql_query\n",
    "    )   \n",
    "    describe_b=REDSHIFT.describe_statement(\n",
    "         Id=response_b['Id'],\n",
    "    )       \n",
    "    status=describe_b['Status']\n",
    "    while status != \"FINISHED\":\n",
    "        time.sleep(1)\n",
    "        describe_b=REDSHIFT.describe_statement(\n",
    "                         Id=response_b['Id'],\n",
    "                    ) \n",
    "        status=describe_b['Status']\n",
    "    max_attempts = 5 \n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            for ids in describe_b['SubStatements']:\n",
    "                result_b = REDSHIFT.get_statement_result(Id=ids['Id'])                \n",
    "                results_list.append(get_redshift_table_result(result_b))\n",
    "            break\n",
    "        except REDSHIFT.exceptions.ResourceNotFoundException as e:\n",
    "            attempts += 1\n",
    "            time.sleep(2)\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c043c-60d0-4d34-8fdd-886d6120c40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_redshift_table_result(response):\n",
    "    \"\"\"\n",
    "    Extracts result data from a Redshift query response and returns it as a CSV string.\n",
    "    Args:\n",
    "        response (dict): The response object from a Redshift query.\n",
    "    Returns:\n",
    "        str: A CSV string containing the result data.\n",
    "    \"\"\"\n",
    "    columns = [c['name'] for c in response['ColumnMetadata']] \n",
    "    data = []\n",
    "    for r in response['Records']:\n",
    "        row = []\n",
    "        for col in r:\n",
    "            row.append(list(col.values())[0])  \n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data, columns=columns)    \n",
    "    return df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24a0b9-ed77-4222-bc87-af828502e2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query_redshift(sql_query, cluster_identifier, database, db_user):\n",
    "    \"\"\"\n",
    "    Execute a SQL query on an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to execute.\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        dict: The response object from executing the SQL query.\n",
    "    \"\"\"\n",
    "    response = REDSHIFT.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c4ef0-9166-4faf-a820-0c03d8974e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_execute_query(sql_query, cluster_identifier, database, db_user,question):\n",
    "    \"\"\"\n",
    "    Execute a single SQL query on an Amazon Redshift cluster and process the result.\n",
    "\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to execute.\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        question (str): A descriptive label or question associated with the query.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the processed result of the SQL query.\n",
    "\n",
    "    \"\"\"\n",
    "    result_sets = []\n",
    "    response = execute_query_redshift(sql_query, cluster_identifier, database, db_user)\n",
    "    df=redshift_querys(sql_query,response,question,params,cluster_identifier, database, db_user,question)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4b2f5-65e8-4c9c-b0bc-f19406d7838c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_debugger(question, statement, error, params): \n",
    "    \"\"\"\n",
    "    Generate debugging guidance and expected SQL correction for a PostgreSQL error.\n",
    "    Args:\n",
    "        question (str): The user's question or intent.\n",
    "        statement (str): The SQL statement that caused the error.\n",
    "        error (str): The error message encountered.\n",
    "        params (dict): Additional parameters including schema, sample data, and length.\n",
    "    Returns:\n",
    "        str: Formatted debugging guidance and expected SQL correction.\n",
    "    \"\"\"\n",
    "    prompts=f'''<s><<SYS>>[INST]\n",
    "You are a PostgreSQL developer who is an expert at debugging errors.  \n",
    "\n",
    "Here are the schema definition of table(s):\n",
    "{params['schema']}\n",
    "#############################\n",
    "Here are example records for each table:\n",
    "{params['sample']}\n",
    "#############################\n",
    "Here is the sql statement that threw the error below:\n",
    "{statement}\n",
    "#############################\n",
    "Here is the error to debug:\n",
    "{error}\n",
    "#############################\n",
    "Here is the intent of the user:\n",
    "{params['prompt']}\n",
    "<</SYS>>\n",
    "First understand the error and think about how you can fix the error.\n",
    "Use the provided schema and sample row to guide your thought process for a solution.\n",
    "Do all this thinking inside <thinking></thinking> XML tags.This is a space for you to write down relevant content and will not be shown to the user.\n",
    "\n",
    "Once your are done debugging, provide the the correct SQL statement without any additional text.\n",
    "When generating the correct SQL statement:\n",
    "1. Pay attention to the schema and table name and use them correctly in your generated sql. \n",
    "2. Never query for all columns from a table unless the question says so. You must query only the columns that are needed to answer the question.\n",
    "3. Wrap each column name in double quotes (\") to denote them as delimited identifiers. Do not use backslash (\\) to escape underscores (_) in column names. \n",
    "\n",
    "Format your response as:\n",
    "<sql> Correct SQL Statement </sql>[/INST]'''\n",
    "\n",
    "    \n",
    "#     prompts=f'''<s> [INST] You are a PostgreSQL developer who is an expert at debugging errors.\n",
    "# Here are the schema definition of table(s):\n",
    "# {params['schema']}\n",
    "# #############################\n",
    "# Here are example records for each table:\n",
    "# {params['sample']}\n",
    "# #############################\n",
    "# Here is the sql statement that threw the error below:\n",
    "# {statement}\n",
    "# #############################\n",
    "# Here is the error to debug:\n",
    "# {error}\n",
    "# #############################\n",
    "# Here is the intent of the user:\n",
    "# {params['prompt']} \n",
    "# First understand the error and think about how you can fix the error.\n",
    "# Use the provided schema and sample row to guide your thought process for a solution.\n",
    "# Do all this thinking inside <thinking></thinking> XML tags.This is a space for you to write down relevant content and will not be shown to the user.\n",
    "# Once your are done debugging, provide the the correct SQL statement without any additional text.\n",
    "# When generating the correct SQL statement:\n",
    "# 1. Pay attention to the database schema and table name and use them correctly in your response. \n",
    "# 2. Never query for all columns from a table unless the question says so. You must query only the columns that are needed to answer the question.\n",
    "# 3. Wrap all column name(s) in double quotes (\") to denote them as delimited identifiers.  \n",
    "# 4. DO NOT escape underscores (_) in column name(s). Just wrap them in double quotes (\").\n",
    "# 5. SQL engine is Amazon Redshift database.\n",
    "\n",
    "# Format your response as:\n",
    "# <sql> Correct SQL Statement </sql> [/INST] '''\n",
    "    answer=query_llm(prompts,round(params['sql-len']))\n",
    "    answer = answer.replace(\"\\\\\",\"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1ae4a-1171-48c4-9799-c0d57566015b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def redshift_querys(q_s,response,prompt,params,cluster_identifier, database, db_user,question): \n",
    "    \"\"\"\n",
    "    Execute a Redshift query, handle errors, debug SQL, and return the result.\n",
    "\n",
    "    Args:\n",
    "        q_s (str): The SQL statement to execute or debug.\n",
    "        response (dict): The response object from executing the SQL statement.\n",
    "        prompt (str): The user's question or intent.\n",
    "        params (dict): Additional parameters including schema, sample data, and length.\n",
    "        cluster_identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        question (str): A descriptive label or question associated with the query.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or str: DataFrame containing the query result, or debugging failure message with no result.\n",
    "\n",
    "    \"\"\"\n",
    "    max_execution=5\n",
    "    attempt_number=0\n",
    "    debug_count=max_execution\n",
    "    try:\n",
    "        statement_result = REDSHIFT.get_statement_result(\n",
    "            Id=response['Id'],\n",
    "\n",
    "        )\n",
    "    except REDSHIFT.exceptions.ResourceNotFoundException as err:  \n",
    "        # print(err)\n",
    "        describe_statement=REDSHIFT.describe_statement(\n",
    "             Id=response['Id'],\n",
    "        )\n",
    "        query_state=describe_statement['Status']  \n",
    "        while query_state in ['SUBMITTED','PICKED','STARTED']:\n",
    "            # print(query_state)\n",
    "            time.sleep(1)\n",
    "            describe_statement=REDSHIFT.describe_statement(\n",
    "                 Id=response['Id'],\n",
    "            )\n",
    "            query_state=describe_statement['Status']\n",
    "        while (max_execution > 0 and query_state == \"FAILED\"):\n",
    "            max_execution = max_execution - 1\n",
    "            attempt_number = 5 - max_execution\n",
    "            print(\"- - - - - - - - - - - - - -\\n\")\n",
    "            print(f\"\\nDEBUG TRIAL {attempt_number}\")\n",
    "            bad_sql=describe_statement['QueryString']\n",
    "            print(f\"\\nBAD SQL:\\n{bad_sql}\")                \n",
    "            error=describe_statement['Error']\n",
    "            print(f\"ERROR:{error}\")\n",
    "            print(\"\\nDEBUGGING...\")\n",
    "            cql=llm_debugger(prompt, bad_sql, error, params)            \n",
    "            idx1 = cql.index('<sql>')\n",
    "            idx2 = cql.index('</sql>')\n",
    "            q_s=cql[idx1 + len('<sql>') + 1: idx2]\n",
    "            print(f\"\\nDEBUGGED SQL {q_s}\")\n",
    "            response = execute_query_redshift(q_s, cluster_identifier, database, db_user)\n",
    "            describe_statement=REDSHIFT.describe_statement(\n",
    "                                 Id=response['Id'],\n",
    "                            )\n",
    "            query_state=describe_statement['Status']\n",
    "            # print(f\"\\n{query_state}\")\n",
    "            while query_state in ['SUBMITTED','PICKED','STARTED']:\n",
    "                time.sleep(2)\n",
    "                # print(f\"\\n{query_state}\")\n",
    "                describe_statement=REDSHIFT.describe_statement(\n",
    "                                 Id=response['Id'],\n",
    "                            )\n",
    "                query_state=describe_statement['Status']\n",
    "            if query_state == \"FINISHED\":                \n",
    "                break \n",
    "        \n",
    "        if max_execution == 0 and query_state == \"FAILED\":\n",
    "            print(f\"DEBUGGING FAILED IN {str(debug_count)} ATTEMPTS\")\n",
    "        else:           \n",
    "            max_attempts = 5\n",
    "            attempts = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    time.sleep(1)\n",
    "                    # print(response['Id'])\n",
    "                    statement_result = REDSHIFT.get_statement_result(\n",
    "                        Id=response['Id']\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "                except REDSHIFT.exceptions.ResourceNotFoundException as e:\n",
    "                    attempts += 1\n",
    "                    time.sleep(5)\n",
    "    if max_execution == 0 and query_state == \"FAILED\":\n",
    "        df=f\"DEBUGGING FAILED IN {str(debug_count)} ATTEMPTS. NO RESULT AVAILABLE\"\n",
    "    else:\n",
    "        df=get_redshift_table_result(statement_result)\n",
    "    return df, q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab616f-b529-4646-961f-0bb1e420e018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def redshift_qna(params):\n",
    "    \"\"\"\n",
    "    Execute a Q&A process for generating SQL queries based on user questions.\n",
    "    Args:\n",
    "        params (dict): A dictionary containing parameters including table name, database name, prompt, etc.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the response, generated SQL statement, and query output.\n",
    "    \"\"\"\n",
    "    # sql1=f\"SELECT * FROM information_schema.columns WHERE table_name='{params['table']}' AND table_schema='{params['db']}'\"\n",
    "    # sql2=f\"SELECT * from dev.{params['db']}.{params['table']} LIMIT 10\"\n",
    "    sql1=f\"SELECT table_catalog,table_schema,table_name,column_name,ordinal_position,is_nullable,data_type FROM information_schema.columns WHERE table_schema='{params['db']}'\"\n",
    "    sql2=[]\n",
    "    for table in params['tables']:\n",
    "        sql2.append(f\"SELECT * from dev.{params['db']}.{table} LIMIT 3\")\n",
    "    sqls=[sql1]+sql2\n",
    "    #print(sqls)\n",
    "    question=params['prompt']\n",
    "    results=execute_query_with_pagination(sqls, CLUSTER_IDENTIFIER, DATABASE, DB_USER)    \n",
    "    \n",
    "    col_names=results[0].split('\\n')[0]\n",
    "    observations=\"\\n\".join(sorted(results[0].split('\\n')[1:])).strip()\n",
    "    params['schema']=f\"{col_names}\\n{observations}\"\n",
    "    params['sample']=''\n",
    "    for examples in results[1:]:\n",
    "        params['sample']+=f\"{examples}\\n\\n\"\n",
    "    # params['schema']=schema\n",
    "    # params['sample']=schema_example\n",
    "    \n",
    "    prompts=f\"\"\"<s><<SYS>>[INST]\n",
    "You are an expert PostgreSQL developer. Your job is to provide a syntactically correct PostgreSQL query given a user question.\n",
    "Here are the schema definition of table(s):\n",
    "########\n",
    "{params['schema']}\n",
    "########\n",
    "\n",
    "Here are example records for each table:\n",
    "##########\n",
    "{params['sample']}\n",
    "###########\n",
    "<</SYS>>\n",
    "Here are some instructions when generating SQL statements:\n",
    "1. Determine the necessary table(s) and schema needed for an accurate query.\n",
    "2. Limit your queries to only the required columns to prevent unnecessary data retrieval and improve query performance.\n",
    "3. For clarity and to prevent potential conflicts, always include the schema name when referencing table names in your SQL queries.\n",
    "4. When working with Amazon Redshift table and column names containing underscores, do not use the backslash escape character (\\). Instead, use double quotes (\"\") to enclose the names in your queries.\n",
    "5. Do not mention 'dev' or 'public' in the queries.\n",
    "In your response, provide a single SQL statement to answer the question, avoid additional text that would cause failure during executing the sql. \n",
    "Format your response as:\n",
    "<sql>\n",
    "generated SQL statement \n",
    "</sql>\n",
    "\n",
    "Question: {question}[/INST]\"\"\"\n",
    "\n",
    "#     prompts=f\"\"\"<s> [INST] You are an expert PostgreSQL developer. Your job is to provide a syntactically correct PostgreSQL query for Amazon Redshift Database.\n",
    "# Here are the schema definition of table(s):\n",
    "# {params['schema']}\n",
    "\n",
    "# Here are example records for each table:\n",
    "# {params['sample']}\n",
    "\n",
    "# Here are some instructions when generating SQL statements:\n",
    "# 1. Pay attention to database schema and table names and use them correctly in your response. \n",
    "# 2. Never query for all columns from a table. You must query only the columns that are needed to answer the question.\n",
    "# 3. Wrap all column name(s) in double quotes (\") to denote them as delimited identifiers. \n",
    "# 4. DO NOT escape underscores (_) in column name(s). Just wrap them in double quotes (\").\n",
    "# In your response, provide a single SQL statement to answer the question, avoid additional text that would cause failure during executing the sql. \n",
    "# Format your response as:\n",
    "# <sql>\n",
    "# generated SQL statement \n",
    "# </sql>\n",
    "# Question: {question} [/INST] \"\"\"\n",
    "\n",
    "    q_s=query_llm(prompts,200)\n",
    "    sql_pattern = re.compile(r'<sql>(.*?)(?:</sql>|$)', re.DOTALL)           \n",
    "    sql_match = re.search(sql_pattern, q_s)\n",
    "    q_s = sql_match.group(1) \n",
    "    q_s = q_s.replace(\"\\\\\",\"\")\n",
    "    print(f\" FIRST ATTEMPT SQL:\\n{q_s}\")\n",
    "    output, q_s=single_execute_query(q_s, CLUSTER_IDENTIFIER, DATABASE, DB_USER,question)    \n",
    "    input_token=mixtral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(output)\n",
    "   \n",
    "    if len(input_token)>28000:    \n",
    "        csv_rows=output.split('\\n')\n",
    "        chunk_rows=chunk_csv_rows(csv_rows, 20000)\n",
    "        initial_summary=[]\n",
    "        for chunk in chunk_rows:\n",
    "            prompts=f'''<s><<SYS>>[INST]You are a helpful and truthful assistant. Your job is provide answers based on samples of a tabular data provided.\n",
    "\n",
    "Here is the tabular data:\n",
    "#######\n",
    "{chunk}\n",
    "#######\n",
    "<</SYS>>\n",
    "Question: {question}\n",
    "\n",
    "When providing your response:\n",
    "- First, review the result to understand the information within. Then provide a complete answer to the my question, based on the result.\n",
    "- If you can't answer the question, please say so[/INST]'''\n",
    "            initial_summary.append(qna_llm(prompts,params))\n",
    "        prompts = f'''<s><<SYS>>[INST]You are a helpful and truthful assistant.\n",
    "\n",
    "Here are multiple answer for a question on different subset of a tabular data:\n",
    "#######\n",
    "{initial_summary}\n",
    "#######\n",
    "<</SYS>>\n",
    "Question: {question}\n",
    "Based on the given question above, merege all answers provided in a coherent singular answer[/INST]'''\n",
    "        response=qna_llm(prompts,params)\n",
    "        \n",
    "    else:        \n",
    "        prompts=f'''<s><<SYS>>[INST]You are a helpful and truthful assistant. Your job is to examine a sql statement and its generated result, then provide a response to my question.\n",
    "\n",
    "Here is the sql query:\n",
    "{q_s}\n",
    "\n",
    "Here is the corresponding sql query result:\n",
    "{output}\n",
    "<</SYS>>\n",
    "question: {question}\n",
    "\n",
    "When providing your response:\n",
    "- First, review the sql query and the corresponding result. Then provide a complete answer to the my question, based on the result.\n",
    "- If you can't answer the question, please say so[/INST]'''\n",
    "        response=qna_llm(prompts, params) \n",
    "    return response, q_s,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fcae3-32f0-4048-a2cf-74183b928182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db=get_db_redshift(CLUSTER_IDENTIFIER, DATABASE, DB_USER)[-1]\n",
    "schm=get_schema_redshift(CLUSTER_IDENTIFIER, db, DB_USER)[-1]\n",
    "tables=get_tables_redshift(CLUSTER_IDENTIFIER, db, DB_USER,schm)\n",
    "db, schm, tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b728224-5821-4ed2-8fb6-796d5c0a7fbf",
   "metadata": {},
   "source": [
    "#### Example prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9087bf8-f6b7-40d9-a849-58bf8d6a2923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = \"Who are the 5 people who spent the most on tickets for events?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec89b7-b910-4532-b929-4c8acb11645c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt2 = \"the top five sellers names in San Diego, based on the number of tickets sold in 2008?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0065583-179c-466c-8f05-a787483a8d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt3 = \"What where the 10 events for which tickets took the longest to sell?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64de7c-e8e7-416b-b60b-694d49481bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt4 = \"the most popular state to host events based on the number of venues per state.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0781d-9ff2-4cd2-b85b-34a4322e96c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt5 = \"Number of Venues where the show Macbeth was held.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5ed6b-ff95-4744-91d1-c3d9b912625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt6 = \"what are the top 10 buyers by quantity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c2dd2-d2a7-4155-ab3d-b6f206cc601a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt7 = \"for the top 10 events, count the number of times each of them occur.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803aff4-7484-4cab-b231-d264e2747fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt8 = \"Total Commissions Generated for Macbeth at Royce Hall.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304c971-ee2c-453c-9358-bd4f0fa371d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entered_text = widgets.Text(\n",
    "    value='',\n",
    "    description='Enter prompt:',\n",
    ")\n",
    "display(entered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baba3e2-8c15-4b08-941f-e28a61094073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = entered_text.value\n",
    "params={'sql-len':700,'text-token':500,'tables':tables,'db':schm,'temp':0.1,'model_id':'mixtral',\n",
    "        \"prompt\":prompt}\n",
    "print(params[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ae516-41e5-453e-be1a-ca7de1c1e9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result_text2sql = redshift_qna(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7a388-c7dd-40df-bda1-3719044129d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query result in Natural Language\n",
    "print(f\"\\nAnswer:\\n\\n{result_text2sql[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66463052-9f25-4ff9-a19e-76832b179e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generated SQL query used\n",
    "print(f\"\\nSQL Query generated from the prompt:\\n\")\n",
    "display(Code(result_text2sql[1], language='sql'))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c31f9-917e-45a3-94fb-1c05eef677b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tabular results from the SQL Query \n",
    "print(f\"\\nTabular results from the SQL query:\\n\")\n",
    "df=pd.read_csv(StringIO(result_text2sql[2]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160c27c-42d3-4e42-8786-0ff748e67bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
